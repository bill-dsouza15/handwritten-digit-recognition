{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcLmp-Oe1wXl",
        "outputId": "0e56769c-3f04-4687-8f74-187bd02ed89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.41.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OHzKXZ9SKBcz"
      },
      "outputs": [],
      "source": [
        "# Import the necessary packages\n",
        "from tensorflow.keras.utils import normalize\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YPE7is8jxf_p"
      },
      "outputs": [],
      "source": [
        "def build_model(width, height, depth, classes):\n",
        "  # Keras' Sequential API\n",
        "  model = Sequential()\n",
        "\n",
        "  # First set of CONV => RELU => POOL layers\n",
        "  model.add(Conv2D(32, (5, 5), padding=\"same\", input_shape=(height, width, depth)))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "  # Second set of CONV => RELU => POOL layers\n",
        "  model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "  # First set of FC => RELU layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  # Second set of FC => RELU layers\n",
        "  model.add(Dense(64))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  # Softmax classifier\n",
        "  model.add(Dense(classes))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  # Return the constructed model\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YmKzphx0naB",
        "outputId": "6b6b328d-84ed-40b2-993d-90a140965649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PROGRESS] Loading MNIST dataset...\n",
            "\n",
            "[PROGRESS] Data transformation\n",
            "x_train - Min: 0.000, Max: 255.000\n",
            "x_test - Min: 0.000, Max: 255.000\n",
            "\n",
            "Scaled x_train - Min: 0.000, Max: 1.000\n",
            "Scaled x_test -Min: 0.000, Max: 1.000\n",
            "\n",
            "[PROGRESS] Compiling model...\n",
            "\n",
            "[PROGRESS] Training network...\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 60s 127ms/step - loss: 0.7726 - accuracy: 0.7365 - val_loss: 0.0941 - val_accuracy: 0.9740\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 59s 126ms/step - loss: 0.2776 - accuracy: 0.9167 - val_loss: 0.0593 - val_accuracy: 0.9824\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.2045 - accuracy: 0.9392 - val_loss: 0.0482 - val_accuracy: 0.9856\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.1750 - accuracy: 0.9487 - val_loss: 0.0459 - val_accuracy: 0.9854\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.1580 - accuracy: 0.9526 - val_loss: 0.0427 - val_accuracy: 0.9872\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.1403 - accuracy: 0.9563 - val_loss: 0.0366 - val_accuracy: 0.9901\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 58s 125ms/step - loss: 0.1269 - accuracy: 0.9626 - val_loss: 0.0372 - val_accuracy: 0.9894\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.1198 - accuracy: 0.9638 - val_loss: 0.0328 - val_accuracy: 0.9905\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.1147 - accuracy: 0.9657 - val_loss: 0.0299 - val_accuracy: 0.9917\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 59s 126ms/step - loss: 0.1020 - accuracy: 0.9689 - val_loss: 0.0289 - val_accuracy: 0.9921\n",
            "\n",
            "[PROGRESS] Evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       0.99      1.00      1.00      1135\n",
            "           2       0.99      1.00      0.99      1032\n",
            "           3       0.99      1.00      0.99      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       0.99      0.99      0.99       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       0.99      0.99      0.99       974\n",
            "           9       1.00      0.98      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "\n",
            "[PROGRESS] Serializing digit model...\n"
          ]
        }
      ],
      "source": [
        "# Initialize the learning rate, number of epochs and batch size\n",
        "LR = 1e-3\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "# Load the MNIST dataset\n",
        "print(\"[PROGRESS] Loading MNIST dataset...\")\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "print(\"\\n[PROGRESS] Data transformation\")\n",
        "# Add a channel dimension to the digits since they dont have one\n",
        "# Channel dimension = 1 (i.e., grayscale)\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
        "\n",
        "# Check range of values\n",
        "print('x_train - Min: %.3f, Max: %.3f' % (x_train.min(), x_train.max()))\n",
        "print('x_test - Min: %.3f, Max: %.3f' % (x_test.min(), x_test.max()))\n",
        "\n",
        "# Scale data to range of [0, 1]\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.0 \n",
        "x_test /= 255.0\n",
        "\n",
        "# Verify that the data has been scaled\n",
        "print('\\nScaled x_train - Min: %.3f, Max: %.3f' % (x_train.min(), x_train.max()))\n",
        "print('Scaled x_test -Min: %.3f, Max: %.3f' % (x_test.min(), x_test.max()))\n",
        "\n",
        "# Convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_test = lb.transform(y_test)\n",
        "\n",
        "\n",
        "# Initialize the optimizer and model\n",
        "print(\"\\n[PROGRESS] Compiling model...\")\n",
        "model = build_model(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=LR), metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Train the network\n",
        "print(\"\\n[PROGRESS] Training network...\")\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "# Evaluate the network\n",
        "print(\"\\n[PROGRESS] Evaluating network...\")\n",
        "y_pred = model.predict(x_test)\n",
        "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
        "\n",
        "\n",
        "# Serialize the model to disk\n",
        "print(\"\\n[PROGRESS] Serializing digit model...\")\n",
        "model.save(\"digit_recognition.h5\", save_format=\"h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "handwritten_digit_recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
